














import sys
from pathlib import Path

PROJECT_ROOT = Path.cwd().parent

if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

DATA_RAW = PROJECT_ROOT / "data" / "raw"
DATA_MERGED = PROJECT_ROOT / "data" / "merged"
DATA_MERGED.mkdir(parents=True, exist_ok=True)

PROJECT_ROOT, DATA_RAW, DATA_MERGED

import pandas as pd

from src.eda import (
    load_github_clickbait,
    load_kaggle_clickbait_data,
    load_kaggle_train2,
    load_kaggle_clickbait_news_detection,
)

from src.vectorization import embed_all








github_df = load_github_clickbait()
k_clickbait_data = load_kaggle_clickbait_data()
k_train2 = load_kaggle_train2()

cbd = load_kaggle_clickbait_news_detection()
cbd_train = cbd.get("train")
cbd_valid = cbd.get("valid")

for name, df in [
    ("github_df", github_df),
    ("k_clickbait_data", k_clickbait_data),
    ("k_train2", k_train2),
    ("cbd_train", cbd_train),
    ("cbd_valid", cbd_valid),
]:
    print(name, df.shape)
    display(df.head())








def normalize_github(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out = out.rename(columns={"title": "title", "label": "label"})
    return out[["title", "label"]]

def normalize_clickbait_data(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out = out.rename(columns={"headline": "title", "clickbait": "label"})
    return out[["title", "label"]]

def normalize_train2(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out = out.rename(columns={"title": "title", "label": "label"})
    out["label"] = out["label"].str.lower().map({"clickbait": 1, "news": 0})
    return out[["title", "label"]].dropna()

def normalize_cbd(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out = out.rename(columns={"title": "title", "label": "label"})
    out["label"] = out["label"].str.lower().map({"clickbait": 1, "news": 0})
    return out[["title", "label"]].dropna()



github_norm = normalize_github(github_df)
clickbait_data_norm = normalize_clickbait_data(k_clickbait_data)
train2_norm = normalize_train2(k_train2)
cbd_train_norm = normalize_cbd(cbd_train)
cbd_valid_norm = normalize_cbd(cbd_valid)

for name, df in [
    ("github_norm", github_norm),
    ("clickbait_data_norm", clickbait_data_norm),
    ("train2_norm", train2_norm),
    ("cbd_train_norm", cbd_train_norm),
    ("cbd_valid_norm", cbd_valid_norm),
]:
    print(name, df.shape, df["label"].value_counts(dropna=False).to_dict())
    display(df.head())








merged_df = pd.concat(
    [
        github_norm,
        clickbait_data_norm,
        train2_norm,
        cbd_train_norm,
        cbd_valid_norm,
    ],
    axis=0,
    ignore_index=True,
)

print("Merged shape:", merged_df.shape)
display(merged_df.head())

print("\nLabel distribution in merged:")
display(merged_df["label"].value_counts(normalize=False).to_frame("count"))









merged_csv = DATA_MERGED / "data_merged.csv"
merged_df.to_csv(merged_csv, index=False)
merged_csv








output_paths = embed_all(
    raw_root=DATA_MERGED,
    embedded_root=DATA_MERGED,
    column=("title", "headline", "targetTitle"),
    batch_size=100,
    output_format="parquet",
    skip_existing=False,
)
output_paths





embed_path = output_paths[0]
embeddings_df = pd.read_parquet(embed_path)
print(embed_path, embeddings_df.shape)
display(embeddings_df.head())



