import pandas as pd
from pathlib import Path
import numpy as np
import joblib
import mlflow
import matplotlib.pyplot as plt
import seaborn as sns
import sys
import os
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix

# --- Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ PATHS ---
# Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï„Î¿Ï… Ï†Î±ÎºÎ­Î»Î¿Ï… src/Models ÏƒÏ„Î¿ path Î³Î¹Î± Î½Î± Î²ÏÎµÎ¹ Ï„Î¿ mlflow_helper
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'Models')))
try:
    import mlflow_helper
except ImportError:
    # Fallback Î±Î½ Ï„ÏÎ­Ï‡ÎµÎ¹ Î±Ï€ÏŒ Î¬Î»Î»Î¿ Ï†Î¬ÎºÎµÎ»Î¿
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    try:
        import mlflow_helper
    except:
        pass # mlflow_helper is optional

# ==========================================
# âš™ï¸ Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ Î§Î¡Î—Î£Î¤Î—
# ==========================================
PROJECT_ROOT = Path(__file__).resolve().parent.parent
# 1. Path Ï„Î¿Ï… Gold Dataset (Test set)
CUSTOM_DATA_PATH = PROJECT_ROOT / "data" / "clean" / "umap" / "custom_news_umap_500.parquet"
TRAIN_DATA_PATH = PROJECT_ROOT / "data" / "clean" / "umap" / "train_umap_500.parquet"

# 3. Î¤Î± Paths Ï„Ï‰Î½ .pkl Î±ÏÏ‡ÎµÎ¯Ï‰Î½
MODELS_TO_EVALUATE = {
    "Gradient_Boosting": {
        "path": PROJECT_ROOT / "mlruns" / "176203313038895818" / "models" / "m-11223ec66e124e829ece6083c7b53cc5" / "artifacts" / "model.pkl"
    },
    "Logistic_Regression_NoScaling": {
        "path": PROJECT_ROOT / "mlruns" / "961020367779049974" / "models" / "m-f5332dd335424d659711f5acb87d7eda" / "artifacts" / "model.pkl",
        "needs_scaling": False
    },
    "SVM_NoScaling": {
        "path": PROJECT_ROOT / "mlruns" / "664524367874882829" / "models" / "m-316b355112e14df284738170b470bf27" / "artifacts" / "ts/model.pkl",
        "needs_scaling": False
    },
    "SGD_Classifier": {
        "path": PROJECT_ROOT / "mlruns" / "236777006947026757" / "models" / "m-022afa5b1f9848768d11c9390253ec71" / "artifacts" / "model.pkl",
        "needs_scaling": False
    },
    "SVM_Scaled": {
        "path": PROJECT_ROOT / "mlruns" / "629225326235206482" / "models" / "m-f917c98e8f4c4e0f895ef460199ce813" / "artifacts" / "model.pkl",
        "needs_scaling": True
    },
    "Logistic_Regression_Scaled": {
        "path": PROJECT_ROOT / "mlruns" / "444470392771103284" / "models" / "m-ad71b18c165c4043b615b5fc234a675d" / "artifacts" / "model.pkl",
        "needs_scaling": True
    },
}

NEW_EXPERIMENT_NAME = "Custom_Dataset_Evaluation"


# ==========================================

def calculate_majority_vote(df):
    """
    Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ Ï„Î¿ Ï„ÎµÎ»Î¹ÎºÏŒ label Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î·Î½ Ï€Î»ÎµÎ¹Î¿ÏˆÎ·Ï†Î¯Î± Ï„Ï‰Î½ annotators (NG, TK, KB).
    """
    annotators = ['NG', 'TK', 'KB']

    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î¿Î¹ ÏƒÏ„Î®Î»ÎµÏ‚
    found_annotators = [col for col in annotators if col in df.columns]

    if len(found_annotators) < 1:
        return None, None

    print(f"   ğŸ‘¥ Î•Î½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎ±Î½ Annotators: {found_annotators}")

    # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ numeric (Î±Î½ ÎµÎ¯Î½Î±Î¹ strings '0', '1')
    for col in found_annotators:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)

    # Majority Vote Logic
    if len(found_annotators) >= 2:
        # Î†Î¸ÏÎ¿Î¹ÏƒÎ¼Î± ÏˆÎ®Ï†Ï‰Î½
        votes = df[found_annotators].sum(axis=1)
        # Î‘Î½ Î¿Î¹ ÏˆÎ®Ï†Î¿Î¹ ÎµÎ¯Î½Î±Î¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Î¼Î¹ÏƒÎ¿ÏÏ‚ (Ï€.Ï‡. >= 2 Î³Î¹Î± 3 Î¬Ï„Î¿Î¼Î±)
        majority_threshold = len(found_annotators) / 2
        y = (votes > majority_threshold).astype(int).values
        print(f"   ğŸ—³ï¸ Majority Vote applied (Threshold > {majority_threshold})")
    else:
        # Î‘Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¼ÏŒÎ½Î¿ Î­Î½Î±Ï‚ annotator, Ï€Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Î±Ï…Ï„ÏŒÎ½
        y = df[found_annotators[0]].values.astype(int)
        print(f"   ğŸ‘¤ Single Annotator used: {found_annotators[0]}")

    return y, "majority_vote"


def load_data(path, is_train=False):
    print(f"   ğŸ“‚ Loading: {os.path.basename(path)}...")
    if not os.path.exists(path):
        print(f"âŒ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: {path}")
        sys.exit(1)

    try:
        df = pd.read_parquet(path, engine='fastparqu # Fallback to pyarrowet')
    except:
        df = pd.read_parquet(path, engine='pyarrow')

    # --- 1. FEATURE DETECTION ---
    # Î¨Î¬Ï‡Î½Î¿Ï…Î¼Îµ Î³Î¹Î± ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… Î¾ÎµÎºÎ¹Î½Î¬Î½Îµ Î¼Îµ "umap_"
    feature_cols = [c for c in df.columns if str(c).startswith("umap_")]

    # Î‘Î½ Î´ÎµÎ½ Î²ÏÎµÎ¸Î¿ÏÎ½, ÏˆÎ¬Ï‡Î½Î¿Ï…Î¼Îµ Î³Î¹Î± ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î‘Î¡Î™Î˜ÎœÎŸÎ™ (Ï€.Ï‡. "0", "1", ... "499")
    if not feature_cols:
        # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¿Ï…Î¼Îµ ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… Ï„Î¿ ÏŒÎ½Î¿Î¼Î¬ Ï„Î¿Ï…Ï‚ ÎµÎ¯Î½Î±Î¹ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚
        # Î ÏÎ¿ÏƒÎ­Ï‡Î¿Ï…Î¼Îµ Î½Î± ÎµÎ¯Î½Î±Î¹ integer strings ("0", "1") Î® integers (0, 1)
        numeric_named_cols = [c for c in df.columns if str(c).isdigit()]

        # Î£Ï…Î½Î®Î¸Ï‰Ï‚ Ï„Î± embeddings ÎµÎ¯Î½Î±Î¹ Î¿Î¹ ÏƒÏ„Î®Î»ÎµÏ‚ 0 Î­Ï‰Ï‚ 499
        if len(numeric_named_cols) >= 50:  # Î‘Î½ Î²ÏÎ¿ÏÎ¼Îµ Ï€Î¿Î»Î»Î­Ï‚ Ï„Î­Ï„Î¿Î¹ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚
            # Î¤Î¹Ï‚ Ï„Î±Î¾Î¹Î½Î¿Î¼Î¿ÏÎ¼Îµ Î³Î¹Î± Î½Î± ÎµÎ¯Î¼Î±ÏƒÏ„Îµ ÏƒÎ¯Î³Î¿Ï…ÏÎ¿Î¹ (0, 1, 2...)
            feature_cols = sorted(numeric_named_cols, key=lambda x: int(x))
            print(f"   âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ 'umap_' prefix. Î§ÏÎ®ÏƒÎ· Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÏÎ½ ÏƒÏ„Î·Î»ÏÎ½ ({len(feature_cols)} dims).")

        # Filter for numeric columns that are not in the exclude list
    # Î‘Î½ Î±ÎºÏŒÎ¼Î± Î´ÎµÎ½ Î²ÏÎ®ÎºÎ±Î¼Îµ, ÏˆÎ¬Ï‡Î½Î¿Ï…Î¼Îµ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ float ÏƒÏ„Î®Î»ÎµÏ‚ (Î­ÏƒÏ‡Î±Ï„Î· Î»ÏÏƒÎ·)
    if not feature_cols:
        exclude = ['NG', 'TK', 'KB', 'label', 'labels', 'target', 'text', 'title']
        feature_cols = [c for c in df.columns if c not in exclude and pd.api.types.is_float_dtype(df[c])]

    if not feature_cols:
        raise ValueError(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ features (embeddings) ÏƒÏ„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿! Î£Ï„Î®Î»ÎµÏ‚: {df.columns.tolist()[:10]}...")

    print(f"   âœ… Features detected: {len(feature_cols)} dimensions.")
    X = df[feature_cols].values.astype(np.float32)

    # --- 2. LABEL DETECTION (Annotators) ---
    y = None
    if not is_train:
        # Î“Î¹Î± Ï„Î¿ Custom Dataset, ÎºÎ¬Î½Î¿Ï…Î¼Îµ Majority Vote
        y, method = calculate_majority_vote(df)

        # Î‘Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ Ï„Î¿ Majority Vote, ÏˆÎ¬Ï‡Î½Î¿Ï…Î¼Îµ Î³Î¹Î± ÎºÎ»Î±ÏƒÎ¹ÎºÏŒ label
        if y is None:
            possible_labels = ['label', 'labels', 'target', 'is_clickbait']
            label_col = next((c for c in possible_labels if c in df.columns), None)
            if label_col:
                y = df[label_col].values.astype(int)
                print(f"   ğŸ·ï¸ Using existing label column: {label_col}")
    else:
        # Î“Î¹Î± Ï„Î¿ Train Dataset, ÏˆÎ¬Ï‡Î½Î¿Ï…Î¼Îµ Ï„Î¿ ÎºÎ»Î±ÏƒÎ¹ÎºÏŒ label
        possible_labels = ['label', 'labels', 'target']
        label_col = next((c for c in possible_labels if c in df.columns), None)
        if label_col:
            y = df[label_col].values.astype(int)

    return X, y


def recreate_scaler(train_path):
    print("\nâš–ï¸  Î‘Î½Î±ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î® StandardScaler Î±Ï€ÏŒ Ï„Î± Training Data...")
    # Î¦Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î± features (is_train=True Î³Î¹Î± Î½Î± Î¼Î·Î½ ÏˆÎ¬Ï‡Î½ÎµÎ¹ annotators)
    X_train, _ = load_data(train_path, is_train=True)

    scaler = StandardScaler()
    scaler.fit(X_train)
    print("âœ… Scaler fitted successfully!")
    return scaler


def evaluate_models():
    # Setup MLflow if available
    if 'mlflow_helper' in sys.modules:
        mlflow_helper.setup_mlflow(NEW_EXPERIMENT_NAME)
    else:
        try:
            mlflow.set_experiment(NEW_EXPERIMENT_NAME)
        except:
            pass

    # 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Custom Dataset (Test set)
    print("\n--- Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Custom Dataset (Greek Annotations) ---")
    X_gold_raw, y_gold = load_data(CUSTOM_DATA_PATH, is_train=False)

    if y_gold is None:
        print("âŒ Î£Ï†Î¬Î»Î¼Î±: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ labels (NG, TK, KB) ÏƒÏ„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿!")
        return

    # 2. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Scaled Î­ÎºÎ´Î¿ÏƒÎ·Ï‚
    scaler = recreate_scaler(TRAIN_DATA_PATH)

    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÏ‰Î½
    if X_gold_raw.shape[1] != scaler.n_features_in_:
        print(f"âŒ Mismatch dimensions! Train: {scaler.n_features_in_}, Custom: {X_gold_raw.shape[1]}")
        print("   Î ÏÎ­Ï€ÎµÎ¹ Î½Î± Î¾Î±Î½Î±Ï„ÏÎ­Î¾ÎµÎ¹Ï‚ Ï„Î¿ UMAP ÏƒÏ„Î¿ custom dataset Î³Î¹Î± Î½Î± Î²Î³Î¬Î»ÎµÎ¹ 500 Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚.")
        return

    X_gold_scaled = scaler.transform(X_gold_raw)

    print(f"\nğŸš€ ÎˆÎ½Î±ÏÎ¾Î· Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ {len(MODELS_TO_EVALUATE)} ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½...")

    results = []

    for model_name, config in MODELS_TO_EVALUATE.items():
        model_path = config["path"]
        needs_scaling = config["needs_scaling"]

        print(f"\nğŸ” Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·: {model_name} ...")

        if not os.path.exists(model_path):
            print(f"   âŒ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ .pkl Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: {model_path}")
            continue

        try:
            # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
            model = joblib.load(model_path)

            # Î•Ï€Î¹Î»Î¿Î³Î® ÏƒÏ‰ÏƒÏ„ÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
            if needs_scaling:
                print("   âš–ï¸  Using SCALED data")
                X_input = X_gold_scaled
            else:
                print("   RAW Using RAW data")
                X_input = X_gold_raw

            # Î ÏÏŒÎ²Î»ÎµÏˆÎ·
            preds = model.predict(X_input)

            # Metrics
            acc = accuracy_score(y_gold, preds)
            f1 = f1_score(y_gold, preds)
            prec = precision_score(y_gold, preds, zero_division=0)
            rec = recall_score(y_gold, preds, zero_division=0)

            print(f"   ğŸ“Š Acc: {acc:.4f} | F1: {f1:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f}")

            # Log to MLflow
            with mlflow.start_run(run_name=f"CustomEval_{model_name}"):
                mlflow.log_param("model_name", model_name)
                mlflow.log_param("dataset", "Custom_Greek_Annotated")

                mlflow.log_metric("custom_accuracy", acc)
                mlflow.log_metric("custom_f1", f1)
                mlflow.log_metric("custom_precision", prec)
                mlflow.log_metric("custom_recall", rec)

                # Confusion Matrix Plot
                cm = confusion_matrix(y_gold, preds)
                plt.figure(figsize=(6, 5))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
                plt.title(f"Confusion Matrix: {model_name}")
                plt.ylabel('True Label (Annotators)')
                plt.xlabel('Predicted Label')
                plt.savefig(f"cm_{model_name}.png")
                mlflow.log_artifact(f"cm_{model_name}.png")
                plt.close()

            results.append({
                "Model": model_name,
                "Accuracy": acc,
                "F1-Score": f1,
                "Precision": prec,
                "Recall": rec
            })

        except Exception as e:
            print(f"   âŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·: {e}")

    if results:
        results_df = pd.DataFrame(results).sort_values(by="F1-Score", ascending=False)
        print("\nğŸ† Î¤ÎµÎ»Î¹ÎºÎ¬ Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÏƒÏ„Î¿ Custom Dataset:")
        print(results_df.to_string(index=False))

        # Save results to CSV for easy copy-paste
        results_df.to_csv("custom_eval_results.csv", index=False)
        print("\nâœ… Î¤Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ ÏƒÏ„Î¿ 'custom_eval_results.csv'")


if __name__ == "__main__":
    evaluate_models()