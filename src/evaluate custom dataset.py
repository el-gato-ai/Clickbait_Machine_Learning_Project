import pandas as pd
import numpy as np
import mlflow
import sys
import os
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score

# --- Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ PATHS ---
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'Models')))
try:
    import mlflow_helper
except ImportError:
    # Fallback Î±Î½ Ï„ÏÎ­Ï‡ÎµÎ¹ Î±Ï€ÏŒ Î¬Î»Î»Î¿ Ï†Î¬ÎºÎµÎ»Î¿
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    import mlflow_helper

# ==========================================
# âš™ï¸ Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ Î§Î¡Î—Î£Î¤Î—
# ==========================================

# 1. Path Ï„Î¿Ï… Gold Dataset (Test set)
CUSTOM_DATA_PATH = r"/Users/nikosgatos/PycharmProjects/Clickbait_Machine_Learning_Project/data/clean/umap/test_umap_500.parquet"

# 2. Path Ï„Î¿Ï… TRAIN Dataset (Î‘Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î¿ Î³Î¹Î± Î½Î± Ï†Ï„Î¹Î¬Î¾Î¿Ï…Î¼Îµ Ï„Î¿Î½ Scaler!)
TRAIN_DATA_PATH = r"/Users/nikosgatos/PycharmProjects/Clickbait_Machine_Learning_Project/data/clean/umap/train_umap_500.parquet"

# 3. Î¤Î± Paths Ï„Ï‰Î½ .pkl Î±ÏÏ‡ÎµÎ¯Ï‰Î½
MODELS_TO_EVALUATE = {
    # ÎœÎ¿Î½Ï„Î­Î»Î± Ï€Î¿Ï… Î¸Î­Î»Î¿Ï…Î½ RAW data (Ï‡Ï‰ÏÎ¯Ï‚ Scaling)
    "SGD_Classifier": {
        "path": r"/Users/nikosgatos/PycharmProjects/Clickbait_Machine_Learning_Project/mlruns/236777006947026757/models/m-022afa5b1f9848768d11c9390253ec71/artifacts/model.pkl",
        "needs_scaling": False
    },
    "Gradient_Boosting": {
        "path": r"/Users/nikosgatos/PycharmProjects/Clickbait_Machine_Learning_Project/mlruns/176203313038895818/models/m-11223ec66e124e829ece6083c7b53cc5/artifacts/model.pkl",
        "needs_scaling": False
    },
    "SVM_NoScaling": {
        "path": r"/Users/nikosgatos/PycharmProjects/Clickbait_Machine_Learning_Project/mlruns/664524367874882829/models/m-316b355112e14df284738170b470bf27/artifacts/model.pkl",
        "needs_scaling": False
    },
    "Logistic_Regression_NoScaling": {
        "path": r"/Users/nikosgatos/PycharmProjects/Clickbait_Machine_Learning_Project/mlruns/961020367779049974/models/m-f5332dd335424d659711f5acb87d7eda/artifacts/model.pkl",
        "needs_scaling": False
    },
    "SVM_Scaled": {
        "path": r"/Users/nikosgatos/PycharmProjects/Clickbait_Machine_Learning_Project/mlruns/629225326235206482/models/m-f917c98e8f4c4e0f895ef460199ce813/artifacts/model.pkl",
        "needs_scaling": True
    },
    "Logistic_Regression_Scaled": {
        "path": r"/Users/nikosgatos/PycharmProjects/Clickbait_Machine_Learning_Project/mlruns/444470392771103284/models/m-ad71b18c165c4043b615b5fc234a675d/artifacts/model.pkl",
        "needs_scaling": True
    },
}

NEW_EXPERIMENT_NAME = "Final_Evaluation_Rescaled"


# ==========================================

def load_data(path):
    print(f"   ğŸ“‚ Loading: {os.path.basename(path)}...")
    if not os.path.exists(path):
        print(f"âŒ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: {path}")
        sys.exit(1)
    try:
        df = pd.read_parquet(path, engine='fastparquet')
    except:
        df = pd.read_parquet(path, engine='pyarrow')

    feature_cols = [c for c in df.columns if c.startswith("umap_")]

    # Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Label (Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹)
    possible_labels = ['label', 'labels', 'target', 'is_clickbait', 'class']
    label_col = next((c for c in possible_labels if c in df.columns), None)

    X = df[feature_cols].values.astype(np.float32)

    y = None
    if label_col:
        y = df[label_col].values.astype(int)

    return X, y


def recreate_scaler(train_path):
    print("\nâš–ï¸  Î‘Î½Î±ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î® StandardScaler Î±Ï€ÏŒ Ï„Î± Training Data...")
    X_train, _ = load_data(train_path)

    scaler = StandardScaler()
    scaler.fit(X_train)  # ÎœÎ±Î¸Î±Î¯Î½Î¿Ï…Î¼Îµ Ï„Î¿ mean/std Î±Ï€ÏŒ Ï„Î¿ training set
    print("âœ… Scaler fitted successfully!")
    return scaler


def evaluate_models():
    mlflow_helper.setup_mlflow(NEW_EXPERIMENT_NAME)

    # 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Gold Dataset (Raw)
    print("\n--- Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ---")
    X_gold_raw, y_gold = load_data(CUSTOM_DATA_PATH)

    # 2. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Scaled Î­ÎºÎ´Î¿ÏƒÎ·Ï‚ Ï„Î¿Ï… Gold Dataset
    # Î¦Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ Ï„Î± train data Î³Î¹Î± Î½Î± ÏÏ…Î¸Î¼Î¯ÏƒÎ¿Ï…Î¼Îµ Ï„Î¿Î½ scaler
    scaler = recreate_scaler(TRAIN_DATA_PATH)
    X_gold_scaled = scaler.transform(X_gold_raw)  # Î•Ï†Î±ÏÎ¼ÏŒÎ¶Î¿Ï…Î¼Îµ Ï„Î¿ scaling ÏƒÏ„Î¿ Gold dataset

    print(f"\nğŸš€ ÎˆÎ½Î±ÏÎ¾Î· Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ {len(MODELS_TO_EVALUATE)} ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½...")

    results = []

    for model_name, config in MODELS_TO_EVALUATE.items():
        model_path = config["path"]
        needs_scaling = config["needs_scaling"]

        print(f"\nğŸ” Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·: {model_name} ...")

        if not os.path.exists(model_path):
            print(f"   âŒ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ .pkl Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ: {model_path}")
            continue

        with mlflow.start_run(run_name=f"Eval_{model_name}"):
            try:
                # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
                model = joblib.load(model_path)

                # Î•Ï€Î¹Î»Î¿Î³Î® ÏƒÏ‰ÏƒÏ„ÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Scaled Î® Raw)
                if needs_scaling:
                    print("   âš–ï¸  Using SCALED data (StandardScaler)")
                    X_input = X_gold_scaled
                else:
                    print("   RAW Using RAW UMAP data (No Scaling)")
                    X_input = X_gold_raw

                # Î ÏÏŒÎ²Î»ÎµÏˆÎ·
                preds = model.predict(X_input)

                acc = accuracy_score(y_gold, preds)
                f1 = f1_score(y_gold, preds)

                print(f"   ğŸ“Š Accuracy: {acc:.4f} | F1: {f1:.4f}")

                mlflow.log_param("model_name", model_name)
                mlflow.log_param("data_scaling", "Scaled" if needs_scaling else "Raw")

                mlflow_helper.evaluate_and_log_metrics(model, X_input, y_gold, prefix="gold")

                results.append({"Model": model_name, "Accuracy": acc, "F1-Score": f1})

            except Exception as e:
                print(f"   âŒ Î£Ï†Î¬Î»Î¼Î±: {e}")

    if results:
        results_df = pd.DataFrame(results)
        print("\nğŸ† Î£Ï…Î³ÎºÎµÎ½Ï„ÏÏ‰Ï„Î¹ÎºÎ¬ Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±:")
        print(results_df)

        plt.figure(figsize=(10, 6))
        sns.barplot(data=results_df, x="Model", y="F1-Score", palette="viridis")
        plt.title("Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½ (F1 Score)")
        plt.tight_layout()
        plt.savefig("benchmark_results_rescaled.png")


if __name__ == "__main__":
    evaluate_models()