{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Clickbait Detection: Logistic Regression (Scaled) & UMAP Embeddings\n",
    "\n",
    "## Î•Î¹ÏƒÎ±Î³Ï‰Î³Î®\n",
    "Î£Ï„Î¿ Ï€Î±ÏÏŒÎ½ notebook Î±Î½Î±Ï€Ï„ÏÏƒÏƒÎ¿Ï…Î¼Îµ ÎºÎ±Î¹ Î±Î¾Î¹Î¿Î»Î¿Î³Î¿ÏÎ¼Îµ Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î¿ **Logistic Regression**.\n",
    "\n",
    "### Î“Î¹Î±Ï„Î¯ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Scaling;\n",
    "Î£Îµ Î±Î½Ï„Î¯Î¸ÎµÏƒÎ· Î¼Îµ Ï„Î± Î´ÎµÎ½Î´ÏÎ¹ÎºÎ¬ Î¼Î¿Î½Ï„Î­Î»Î± (Ï€.Ï‡. Gradient Boosting) Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î±Î´Î¹Î¬Ï†Î¿ÏÎ± ÏƒÏ„Î·Î½ ÎºÎ»Î¯Î¼Î±ÎºÎ±, Î· Logistic Regression ÎµÏ€Î·ÏÎµÎ¬Î¶ÎµÏ„Î±Î¹ Î­Î½Ï„Î¿Î½Î± Î±Ï€ÏŒ Ï„Î¿ ÎµÏÏÎ¿Ï‚ Ï„Ï‰Î½ Ï„Î¹Î¼ÏÎ½, ÎºÎ±Î¸ÏÏ‚ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…Ï‚ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ (solvers ÏŒÏ€Ï‰Ï‚ `saga`, `lbfgs`) Ï€Î¿Ï… Î²Î±ÏƒÎ¯Î¶Î¿Î½Ï„Î±Î¹ ÏƒÎµ Ï€Î±ÏÎ±Î³ÏÎ³Î¿Ï…Ï‚.\n",
    "\n",
    "Î“Î¹Î± Î½Î± ÏƒÏ…Î³ÎºÎ»Î¯Î½ÎµÎ¹ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎºÎ±Î¹ Î½Î± Î±Ï€Î¿Î´ÏÏƒÎµÎ¹ ÏƒÏ‰ÏƒÏ„Î¬ ÏƒÏ„Î± UMAP embeddings, ÎµÏ†Î±ÏÎ¼ÏŒÎ¶Î¿Ï…Î¼Îµ **`StandardScaler`** (z-score normalization).\n",
    "\n",
    "## Î£Ï„ÏŒÏ‡Î¿Î¹\n",
    "1. **Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½**: Î§ÏÎ®ÏƒÎ· Ï„Ï‰Î½ UMAP-500 parquets.\n",
    "2. **Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· (Optuna)**: Î•ÏÏÎµÏƒÎ· Ï€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½ (`C`, `penalty`, `solver`) Î¼Îµ ÎµÎ½ÏƒÏ‰Î¼Î±Ï„Ï‰Î¼Î­Î½Î¿ Scaling Î±Î½Î¬ trial.\n",
    "3. **Champion Model**: Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Ï„Î¿Ï… Ï„ÎµÎ»Î¹ÎºÎ¿Ï Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ÏƒÏ„Î¿ ÏƒÏÎ½Î¿Î»Î¿ Train+Valid.\n",
    "4. **Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Artifacts**: Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Î¿Ï… ÎœÎ¿Î½Ï„Î­Î»Î¿Ï… ÎšÎ‘Î™ Ï„Î¿Ï… Scaler (Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î¿ Î³Î¹Î± Ï‡ÏÎ®ÏƒÎ· ÏƒÎµ Î½Î­Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±)."
   ],
   "id": "6a999d3cf340c5ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import mlflow\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Î‘Ï€ÏŒÎºÏÏ…ÏˆÎ· FutureWarnings Î³Î¹Î± ÎºÎ±Î¸Î±ÏÏŒ output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "\n",
    "# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Paths Î³Î¹Î± Î½Î± Î²ÏÎ¿ÏÎ¼Îµ Ï„Î¿ mlflow_helper ÎºÎ±Î¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±\n",
    "# Î¥Ï€Î¿Î¸Î­Ï„Î¿Ï…Î¼Îµ ÏŒÏ„Î¹ Ï„Î¿ notebook ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î¿ Ï†Î¬ÎºÎµÎ»Î¿: src/Notebooks\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import mlflow_helper\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../..'))\n",
    "DATA_FOLDER = os.path.join(project_root, 'data', 'clean', 'umap')\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Data Folder: {DATA_FOLDER}\")"
   ],
   "id": "d0121e9b0daeba3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½\n",
    "\n",
    "Î¦Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ Ï„Î± Train/Valid/Test sets.\n",
    "**Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·:** Î•Î´Ï Ï†Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ Ï„Î± \"Ï‰Î¼Î¬\" Î´ÎµÎ´Î¿Î¼Î­Î½Î±. Î¤Î¿ Scaling Î¸Î± ÎµÏ†Î±ÏÎ¼Î¿ÏƒÏ„ÎµÎ¯ Î´Ï…Î½Î±Î¼Î¹ÎºÎ¬ ÏƒÏ„Î± ÎµÏ€ÏŒÎ¼ÎµÎ½Î± Î²Î®Î¼Î±Ï„Î± Î³Î¹Î± Î½Î± Î±Ï€Î¿Ï†ÏÎ³Î¿Ï…Î¼Îµ Ï„Î¿ Data Leakage (Î´Î¹Î±ÏÏÎ¿Î® Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±Ï‚ Î±Ï€ÏŒ Ï„Î¿ test set)."
   ],
   "id": "6b433f0be10bdd6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_split_data(data_path):\n",
    "    files = {\n",
    "        \"Train\": \"train_umap_500.parquet\",\n",
    "        \"Valid\": \"valid_umap_500.parquet\",\n",
    "        \"Test\":  \"test_umap_500.parquet\"\n",
    "    }\n",
    "\n",
    "    loaded_data = {}\n",
    "    possible_label_cols = ['labels', 'label', 'target', 'class', 'is_clickbait']\n",
    "\n",
    "    print(f\"â³ ÎˆÎ½Î±ÏÎ¾Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î±Ï€ÏŒ: {data_path}\")\n",
    "\n",
    "    for name, filename in files.items():\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ {filename} Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ.\")\n",
    "\n",
    "        try:\n",
    "            df = pd.read_parquet(file_path, engine='fastparquet')\n",
    "        except:\n",
    "            df = pd.read_parquet(file_path, engine='pyarrow')\n",
    "\n",
    "        # 1. Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Features\n",
    "        feature_cols = [c for c in df.columns if c.startswith(\"umap_\")]\n",
    "        if not feature_cols:\n",
    "            feature_cols = [c for c in df.columns if c not in possible_label_cols]\n",
    "\n",
    "        # 2. Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Label\n",
    "        label_col = None\n",
    "        for col in possible_label_cols:\n",
    "            if col in df.columns:\n",
    "                label_col = col\n",
    "                break\n",
    "\n",
    "        if label_col is None:\n",
    "             raise ValueError(f\"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ label ÏƒÏ„Î®Î»Î· ÏƒÏ„Î¿ {filename}\")\n",
    "\n",
    "        # Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ X, y\n",
    "        if label_col in feature_cols:\n",
    "            feature_cols.remove(label_col)\n",
    "\n",
    "        y = df[label_col].values.astype(int)\n",
    "        X = df[feature_cols].values.astype(np.float32)\n",
    "\n",
    "        loaded_data[name] = (X, y)\n",
    "        print(f\"   âœ… [{name}] Loaded: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "    return loaded_data[\"Train\"], loaded_data[\"Valid\"], loaded_data[\"Test\"]\n",
    "\n",
    "# Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î¦ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = load_split_data(DATA_FOLDER)"
   ],
   "id": "4957153534e5be9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¥Ï€ÎµÏÏ€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½ (Tuning)\n",
    "\n",
    "ÎŸÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· `objective` Î³Î¹Î± Ï„Î¿ Optuna.\n",
    "**ÎšÏÎ¯ÏƒÎ¹Î¼Î¿ Î’Î®Î¼Î±:** Î•Î´Ï Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Ï„Î¿Î½ `StandardScaler` ÎºÎ±Î¹ Ï„Î¿Î½ ÎºÎ¬Î½Î¿Ï…Î¼Îµ `.fit()` **Î¼ÏŒÎ½Î¿** ÏƒÏ„Î¿ Training ÎºÎ¿Î¼Î¼Î¬Ï„Î¹ Ï„Î¿Ï… ÎµÎºÎ¬ÏƒÏ„Î¿Ï„Îµ trial. Î¤Î¿ Validation set Î³Î¯Î½ÎµÏ„Î±Î¹ Î±Ï€Î»ÏÏ‚ `.transform()`."
   ],
   "id": "26229852b8f1bc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def objective(trial, X_tr, y_tr, X_v, y_v):\n",
    "    # --- 1. Hyperparameters Space ---\n",
    "    C = trial.suggest_float(\"C\", 1e-4, 1e2, log=True)\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l2\", \"l1\", \"elasticnet\"])\n",
    "    solver = trial.suggest_categorical(\"solver\", [\"lbfgs\", \"liblinear\", \"saga\"])\n",
    "    class_weight = trial.suggest_categorical(\"class_weight\", [None, \"balanced\"])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 500, 3000) # Î‘Ï…Î¾Î·Î¼Î­Î½Î¿ Î³Î¹Î± ÏƒÏÎ³ÎºÎ»Î¹ÏƒÎ·\n",
    "\n",
    "    # --- 2. Constraints (Pruning invalid combinations) ---\n",
    "    if penalty == \"elasticnet\" and solver != \"saga\":\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    if penalty == \"l1\" and solver == \"lbfgs\":\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    l1_ratio = None\n",
    "    if penalty == \"elasticnet\":\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "\n",
    "    # --- 3. Scaling (Î•Î½Ï„ÏŒÏ‚ Ï„Î¿Ï… Trial) ---\n",
    "    scaler = StandardScaler()\n",
    "    X_tr_sc = scaler.fit_transform(X_tr) # Fit ÏƒÏ„Î¿ Train\n",
    "    X_v_sc = scaler.transform(X_v)       # Transform ÏƒÏ„Î¿ Valid\n",
    "\n",
    "    # --- 4. Model Setup ---\n",
    "    params = dict(\n",
    "        C=C, penalty=penalty, solver=solver,\n",
    "        class_weight=class_weight,\n",
    "        max_iter=max_iter, random_state=42\n",
    "    )\n",
    "    if l1_ratio is not None:\n",
    "        params[\"l1_ratio\"] = l1_ratio\n",
    "\n",
    "    model = LogisticRegression(**params)\n",
    "\n",
    "    # --- 5. Training & Eval ---\n",
    "    t0 = time.time()\n",
    "    model.fit(X_tr_sc, y_tr)\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    preds = model.predict(X_v_sc)\n",
    "    f1 = f1_score(y_v, preds)\n",
    "    acc = accuracy_score(y_v, preds)\n",
    "\n",
    "    metrics = {\"val_f1\": f1, \"val_accuracy\": acc, \"training_time_sec\": train_time}\n",
    "\n",
    "    # ÎšÎ±Ï„Î±Î³ÏÎ±Ï†Î® ÏƒÏ„Î¿ MLflow\n",
    "    params_to_log = params.copy()\n",
    "    params_to_log[\"scaler\"] = \"StandardScaler\" # Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ· ÏŒÏ„Î¹ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎµ scaler\n",
    "\n",
    "    mlflow_helper.log_optuna_trial(trial, params_to_log, metrics, model, run_name_prefix=\"LR_Trial\")\n",
    "\n",
    "    return f1"
   ],
   "id": "6bdd5f02e609c686"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î ÎµÎ¹ÏÎ¬Î¼Î±Ï„Î¿Ï‚ & Champion Model\n",
    "\n",
    "1. Î¤ÏÎ­Ï‡Î¿Ï…Î¼Îµ Ï„Î¿ **Tuning** (20 trials).\n",
    "2. Î•Ï€Î¹Î»Î­Î³Î¿Ï…Î¼Îµ Ï„Î¹Ï‚ Î²Î­Î»Ï„Î¹ÏƒÏ„ÎµÏ‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚.\n",
    "3. **Î•Ï€Î±Î½ÎµÎºÏ€Î±Î¹Î´ÎµÏÎ¿Ï…Î¼Îµ** ÏƒÏ„Î¿ Ï€Î»Î®ÏÎµÏ‚ ÏƒÎµÏ„ (Train + Valid).\n",
    "4. **Î£Î·Î¼Î±Î½Ï„Î¹ÎºÏŒ:** Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎ¿Ï…Î¼Îµ Ï„Î¿Î½ `scaler.pkl` Î¼Î±Î¶Î¯ Î¼Îµ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿, ÏÏƒÏ„Îµ Î½Î± Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ Î±ÏÎ³ÏŒÏ„ÎµÏÎ± (Ï€.Ï‡. ÏƒÏ„Î¿ evaluation script)."
   ],
   "id": "781a79e318d77d22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EXPERIMENT_NAME = \"Clickbait_LogReg_UMAP500_Optuna_Scaled\"\n",
    "mlflow_helper.setup_mlflow(EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"\\nğŸš€ ÎˆÎ½Î±ÏÎ¾Î· Î ÎµÎ¹ÏÎ¬Î¼Î±Ï„Î¿Ï‚: {EXPERIMENT_NAME}\")\n",
    "\n",
    "# --- Î¦Î‘Î£Î— 1: Tuning ---\n",
    "print(\"\\nğŸ” [Î¦Î‘Î£Î— 1] Hyperparameter Tuning...\")\n",
    "with mlflow.start_run(run_name=\"LR_Hyperparameter_Tuning\"):\n",
    "    mlflow.log_param(\"dataset\", \"UMAP_500\")\n",
    "    mlflow.log_param(\"scaler\", \"StandardScaler\")\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(\n",
    "        lambda t: objective(t, X_train, y_train, X_val, y_val),\n",
    "        n_trials=20,\n",
    "        catch=(optuna.exceptions.TrialPruned,)\n",
    "    )\n",
    "\n",
    "    print(\"ğŸ† Best F1:\", study.best_value)\n",
    "    print(\"ğŸ† Best Params:\", study.best_params)\n",
    "\n",
    "\n",
    "# --- Î¦Î‘Î£Î— 2: Champion Model ---\n",
    "print(\"\\nğŸ‘‘ [Î¦Î‘Î£Î— 2] Champion Model Training...\")\n",
    "with mlflow.start_run(run_name=\"LR_Champion_Model\") as final_run:\n",
    "    best = study.best_params\n",
    "\n",
    "    # 1. Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Full Train)\n",
    "    X_full = np.vstack([X_train, X_val])\n",
    "    y_full = np.concatenate([y_train, y_val])\n",
    "\n",
    "    # 2. Final Scaling (Fit ÏƒÏ„Î¿ Full Dataset)\n",
    "    scaler = StandardScaler()\n",
    "    X_full_sc = scaler.fit_transform(X_full)\n",
    "    X_test_sc = scaler.transform(X_test) # Transform Ï„Î¿ Test Î¼Îµ Ï„Î¿Î½ Î¯Î´Î¹Î¿ scaler\n",
    "\n",
    "    # 3. Setup Model\n",
    "    champion_params = dict(\n",
    "        C=best[\"C\"], penalty=best[\"penalty\"], solver=best[\"solver\"],\n",
    "        class_weight=best[\"class_weight\"],\n",
    "        max_iter=best[\"max_iter\"], random_state=42\n",
    "    )\n",
    "    if best[\"penalty\"] == \"elasticnet\":\n",
    "        champion_params[\"l1_ratio\"] = best[\"l1_ratio\"]\n",
    "\n",
    "    final_model = LogisticRegression(**champion_params)\n",
    "\n",
    "    # 4. Training\n",
    "    t0 = time.time()\n",
    "    final_model.fit(X_full_sc, y_full)\n",
    "    final_train_time = time.time() - t0\n",
    "\n",
    "    # 5. Logging\n",
    "    mlflow.log_params(champion_params)\n",
    "    mlflow.log_param(\"scaler\", \"StandardScaler\")\n",
    "\n",
    "    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Î¿Ï… Scaler Ï‰Ï‚ artifact!\n",
    "    with open(\"scaler.pkl\", \"wb\") as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    mlflow.log_artifact(\"scaler.pkl\")\n",
    "\n",
    "    mlflow.sklearn.log_model(final_model, artifact_path=\"champion_model\")\n",
    "\n",
    "    # 6. Evaluation\n",
    "    print(\"ğŸ“ˆ Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÏƒÏ„Î¿ Test Set...\")\n",
    "    mlflow_helper.evaluate_and_log_metrics(\n",
    "        final_model,\n",
    "        X_test_sc, # Î ÏÎ¿ÏƒÎ¿Ï‡Î®: Î”Î¯Î½Î¿Ï…Î¼Îµ Ï„Î± SCALED Î´ÎµÎ´Î¿Î¼Î­Î½Î±\n",
    "        y_test,\n",
    "        prefix=\"test\",\n",
    "        training_time=final_train_time\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ. Run ID: {final_run.info.run_id}\")"
   ],
   "id": "f0b0a0355a90f05b"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
