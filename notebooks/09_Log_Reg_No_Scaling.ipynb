{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Clickbait Detection: Logistic Regression (No Scaling) & UMAP Embeddings\n",
    "\n",
    "## Î•Î¹ÏƒÎ±Î³Ï‰Î³Î®\n",
    "Î£Ï„Î¿ Ï€Î±ÏÏŒÎ½ notebook Î±Î½Î±Ï€Ï„ÏÏƒÏƒÎ¿Ï…Î¼Îµ ÎºÎ±Î¹ Î±Î¾Î¹Î¿Î»Î¿Î³Î¿ÏÎ¼Îµ Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î¿ **Logistic Regression** Ï‡Ï‰ÏÎ¯Ï‚ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î® ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ (Scaling).\n",
    "\n",
    "### Î“Î¹Î±Ï„Î¯ \"No Scaling\";\n",
    "Î Î±ÏÏŒÎ»Î¿ Ï€Î¿Ï… Î· Logistic Regression ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ Î±Ï€Î±Î¹Ï„ÎµÎ¯ Scaling, Ï„Î± Ï€ÎµÎ¹ÏÎ±Î¼Î±Ï„Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î­Î´ÎµÎ¹Î¾Î±Î½ ÏŒÏ„Î¹ ÏƒÏ„Î± **UMAP Embeddings**, Î· ÎµÏ†Î±ÏÎ¼Î¿Î³Î® `StandardScaler` ÎºÎ±Ï„Î±ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î· Î³ÎµÏ‰Î¼ÎµÏ„ÏÎ¹ÎºÎ® Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î± (Ï€Ï…ÎºÎ½ÏŒÏ„Î·Ï„Î±/Î±Ï€Î¿ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚).\n",
    "Î•Ï€Î¿Î¼Î­Î½Ï‰Ï‚, ÎµÎ´Ï Î´Î¿ÎºÎ¹Î¼Î¬Î¶Î¿Ï…Î¼Îµ Ï„Î·Î½ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· ÏƒÏ„Î± \"Ï‰Î¼Î¬\" Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï„Î¿Ï… UMAP, Î±Î½Î±Î¼Î­Î½Î¿Î½Ï„Î±Ï‚ Ï…ÏˆÎ·Î»ÏŒÏ„ÎµÏÎ· ÎµÏ€Î¯Î´Î¿ÏƒÎ·.\n",
    "\n",
    "## Î£Ï„ÏŒÏ‡Î¿Î¹\n",
    "1. **Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½**: Î§ÏÎ®ÏƒÎ· Ï„Ï‰Î½ UMAP-500 parquets (Ï‡Ï‰ÏÎ¯Ï‚ Ï€ÎµÏÎ±Î¹Ï„Î­ÏÏ‰ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±).\n",
    "2. **Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· (Optuna)**: Î•ÏÏÎµÏƒÎ· Ï€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½ (`C`, `penalty`, `solver`) Î±Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ ÏƒÏ„Î± raw embeddings.\n",
    "3. **Champion Model**: Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Ï„Î¿Ï… Ï„ÎµÎ»Î¹ÎºÎ¿Ï Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ÏƒÏ„Î¿ ÏƒÏÎ½Î¿Î»Î¿ Train+Valid."
   ],
   "id": "13de63821584ec4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import mlflow\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Î‘Ï€ÏŒÎºÏÏ…ÏˆÎ· FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "\n",
    "# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Paths\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import mlflow_helper\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../..'))\n",
    "DATA_FOLDER = os.path.join(project_root, 'data', 'clean', 'umap')\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Data Folder: {DATA_FOLDER}\")"
   ],
   "id": "49029e56a4971ccf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½\n",
    "\n",
    "Î¦Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ Ï„Î± Train/Valid/Test sets.\n",
    "**Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·:** Î”ÎµÎ½ ÎµÏ†Î±ÏÎ¼ÏŒÎ¶Î¿Ï…Î¼Îµ ÎºÎ±Î¼Î¯Î± Î¼Î­Î¸Î¿Î´Î¿ Scaling. Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¹ÏƒÎ¬Î³Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î±ÎºÏÎ¹Î²ÏÏ‚ ÏŒÏ€Ï‰Ï‚ Ï€Î±ÏÎ®Ï‡Î¸Î·ÏƒÎ±Î½ Î±Ï€ÏŒ Ï„Î¿ UMAP."
   ],
   "id": "eb2f5bd4d0691a77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_split_data(data_path):\n",
    "    files = {\n",
    "        \"Train\": \"train_umap_500.parquet\",\n",
    "        \"Valid\": \"valid_umap_500.parquet\",\n",
    "        \"Test\":  \"test_umap_500.parquet\"\n",
    "    }\n",
    "\n",
    "    loaded_data = {}\n",
    "    possible_label_cols = ['labels', 'label', 'target', 'class', 'is_clickbait']\n",
    "\n",
    "    print(f\"â³ ÎˆÎ½Î±ÏÎ¾Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î±Ï€ÏŒ: {data_path}\")\n",
    "\n",
    "    for name, filename in files.items():\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ {filename} Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ.\")\n",
    "\n",
    "        try:\n",
    "            df = pd.read_parquet(file_path, engine='fastparquet')\n",
    "        except:\n",
    "            df = pd.read_parquet(file_path, engine='pyarrow')\n",
    "\n",
    "        # 1. Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Features\n",
    "        feature_cols = [c for c in df.columns if c.startswith(\"umap_\")]\n",
    "        if not feature_cols:\n",
    "            feature_cols = [c for c in df.columns if c not in possible_label_cols]\n",
    "\n",
    "        # 2. Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Label\n",
    "        label_col = None\n",
    "        for col in possible_label_cols:\n",
    "            if col in df.columns:\n",
    "                label_col = col\n",
    "                break\n",
    "\n",
    "        if label_col is None:\n",
    "             raise ValueError(f\"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ label ÏƒÏ„Î®Î»Î· ÏƒÏ„Î¿ {filename}\")\n",
    "\n",
    "        if label_col in feature_cols:\n",
    "            feature_cols.remove(label_col)\n",
    "\n",
    "        y = df[label_col].values.astype(int)\n",
    "        X = df[feature_cols].values.astype(np.float32)\n",
    "\n",
    "        loaded_data[name] = (X, y)\n",
    "        print(f\"   âœ… [{name}] Loaded: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "    return loaded_data[\"Train\"], loaded_data[\"Valid\"], loaded_data[\"Test\"]\n",
    "\n",
    "# Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î¦ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = load_split_data(DATA_FOLDER)"
   ],
   "id": "3be0c23b36081dbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¥Ï€ÎµÏÏ€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½ (Tuning)\n",
    "\n",
    "ÎŸÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· `objective`.\n",
    "* Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿Î½ solver `saga` Ï€Î¿Ï… Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ ÏŒÎ»Î± Ï„Î± penalties (l1, l2, elasticnet).\n",
    "* Î‘Ï…Î¾Î¬Î½Î¿Ï…Î¼Îµ Ï„Î¿ `max_iter` ÏƒÏ„Î¿ **2000** Î³Î¹Î± Î½Î± Î²Î¿Î·Î¸Î®ÏƒÎ¿Ï…Î¼Îµ Ï„Î· ÏƒÏÎ³ÎºÎ»Î¹ÏƒÎ·, ÎºÎ±Î¸ÏÏ‚ Î· Î­Î»Î»ÎµÎ¹ÏˆÎ· scaling Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎºÎ¬Î½ÎµÎ¹ Ï„Î· Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï€Î¹Î¿ Î±ÏÎ³Î®.\n",
    "* **Î”ÎµÎ½ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ StandardScaler.**"
   ],
   "id": "75e3329c06780dd8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def objective(trial, X_tr, y_tr, X_v, y_v):\n",
    "    # --- 1. Hyperparameters Space ---\n",
    "    # ÎŸ 'saga' ÎµÎ¯Î½Î±Î¹ Î¿ Ï€Î¹Î¿ ÎµÏ…Î­Î»Î¹ÎºÏ„Î¿Ï‚ solver Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î± datasets\n",
    "    solver = \"saga\"\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"])\n",
    "    C = trial.suggest_float(\"C\", 1e-4, 10.0, log=True)\n",
    "\n",
    "    # Î‘Ï…Î¾Î¬Î½Î¿Ï…Î¼Îµ Ï„Î± iterations Î³Î¹Î±Ï„Î¯ Ï‡Ï‰ÏÎ¯Ï‚ scaling Î· ÏƒÏÎ³ÎºÎ»Î¹ÏƒÎ· ÎµÎ¯Î½Î±Î¹ Ï€Î¹Î¿ Î´ÏÏƒÎºÎ¿Î»Î·\n",
    "    max_iter = 2000\n",
    "\n",
    "    # --- 2. Model Setup ---\n",
    "    params = dict(\n",
    "        solver=solver,\n",
    "        penalty=penalty,\n",
    "        C=C,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    if penalty == \"elasticnet\":\n",
    "        params[\"l1_ratio\"] = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "\n",
    "    model = LogisticRegression(**params)\n",
    "\n",
    "    # --- 3. Training & Eval (NO SCALING) ---\n",
    "    t0 = time.time()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    preds = model.predict(X_v)\n",
    "    f1 = f1_score(y_v, preds)\n",
    "    acc = accuracy_score(y_v, preds)\n",
    "\n",
    "    metrics = {\"val_f1\": f1, \"val_accuracy\": acc, \"training_time_sec\": training_time}\n",
    "\n",
    "    # Log param: No Scaling\n",
    "    params_to_log = params.copy()\n",
    "    params_to_log[\"scaler\"] = \"None\"\n",
    "\n",
    "    mlflow_helper.log_optuna_trial(trial, params_to_log, metrics, model, run_name_prefix=\"LR_Trial\")\n",
    "\n",
    "    return f1"
   ],
   "id": "beb004cc2b52f1b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î ÎµÎ¹ÏÎ¬Î¼Î±Ï„Î¿Ï‚ & Champion Model\n",
    "\n",
    "1. **Tuning:** 20 trials Î³Î¹Î± ÎµÏÏÎµÏƒÎ· Ï„Î¿Ï… Î²Î­Î»Ï„Î¹ÏƒÏ„Î¿Ï… ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼Î¿Ï (Regularization strength `C`, Penalty type).\n",
    "2. **Champion Model:** Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ Ï€Î»Î®ÏÎµÏ‚ dataset (Train + Valid) Ï‡Ï‰ÏÎ¯Ï‚ scaling.\n",
    "3. **Evaluation:** Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÏƒÏ„Î¿ Test set."
   ],
   "id": "66776d720fb724fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EXPERIMENT_NAME = \"Clickbait_LR_UMAP_NoScaling\"\n",
    "mlflow_helper.setup_mlflow(EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"\\nğŸš€ ÎˆÎ½Î±ÏÎ¾Î· Î ÎµÎ¹ÏÎ¬Î¼Î±Ï„Î¿Ï‚: {EXPERIMENT_NAME}\")\n",
    "\n",
    "# --- Î¦Î‘Î£Î— 1: Tuning ---\n",
    "print(\"\\nğŸ” [Î¦Î‘Î£Î— 1] Hyperparameter Tuning...\")\n",
    "with mlflow.start_run(run_name=\"LR_Hyperparameter_Tuning\"):\n",
    "    mlflow.log_param(\"dataset\", \"UMAP_500\")\n",
    "    mlflow.log_param(\"scaling\", \"None\") # Explicitly log No Scaling\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "\n",
    "    study.optimize(\n",
    "        lambda t: objective(t, X_train, y_train, X_val, y_val),\n",
    "        n_trials=20\n",
    "    )\n",
    "\n",
    "    print(\"ğŸ† Best F1:\", study.best_value)\n",
    "    print(\"ğŸ† Best Params:\", study.best_params)\n",
    "\n",
    "\n",
    "# --- Î¦Î‘Î£Î— 2: Champion Model ---\n",
    "print(\"\\nğŸ‘‘ [Î¦Î‘Î£Î— 2] Champion Model Training...\")\n",
    "with mlflow.start_run(run_name=\"LR_Champion_Model\") as final_run:\n",
    "    best = study.best_params\n",
    "\n",
    "    # 1. Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Full Train - No Scaling)\n",
    "    X_full = np.vstack([X_train, X_val])\n",
    "    y_full = np.concatenate([y_train, y_val])\n",
    "\n",
    "    # 2. Setup Model\n",
    "    champion_params = dict(\n",
    "        solver=\"saga\",\n",
    "        penalty=best[\"penalty\"],\n",
    "        C=best[\"C\"],\n",
    "        max_iter=2000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    if best[\"penalty\"] == \"elasticnet\":\n",
    "        champion_params[\"l1_ratio\"] = best[\"l1_ratio\"]\n",
    "\n",
    "    final_model = LogisticRegression(**champion_params)\n",
    "\n",
    "    # 3. Training\n",
    "    t0 = time.time()\n",
    "    final_model.fit(X_full, y_full)\n",
    "    final_train_time = time.time() - t0\n",
    "\n",
    "    # 4. Logging\n",
    "    mlflow.log_params(champion_params)\n",
    "    mlflow.log_param(\"scaler\", \"None\")\n",
    "    mlflow.sklearn.log_model(final_model, artifact_path=\"champion_model\")\n",
    "\n",
    "    # 5. Evaluation\n",
    "    print(\"ğŸ“ˆ Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÏƒÏ„Î¿ Test Set...\")\n",
    "    mlflow_helper.evaluate_and_log_metrics(\n",
    "        final_model,\n",
    "        X_test, # Raw UMAP data\n",
    "        y_test,\n",
    "        prefix=\"test\",\n",
    "        training_time=final_train_time\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ. Run ID: {final_run.info.run_id}\")"
   ],
   "id": "eb86bb833c762817"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
